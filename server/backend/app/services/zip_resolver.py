import os
import shutil
import zipfile
import glob
import yaml  # pip install pyyaml

IMAGE_EXT = {".png", ".jpg", ".jpeg", ".bmp", ".gif"}
TEXT_EXT = {".txt", ".md", ".jsonl"}
CSV_EXT = {".csv", ".tsv"}
VIDEO_EXT = {".mp4", ".mov", ".avi", ".mkv"}

# Ï†úÍ±∞Ìï† Î∂àÌïÑÏöîÌïú ÌååÏùº/Ìè¥Îçî
JUNK_FOLDERS = {"__MACOSX", ".git", ".svn", "__pycache__", ".idea"}
JUNK_FILES = {".DS_Store", "Thumbs.db", ".gitkeep", ".gitignore"}
JUNK_PREFIXES = ("._",)  # macOS Î¶¨ÏÜåÏä§ Ìè¨ÌÅ¨ ÌååÏùº


def _is_junk(name: str) -> bool:
    """Î∂àÌïÑÏöîÌïú ÌååÏùº/Ìè¥ÎçîÏù∏ÏßÄ ÌôïÏù∏"""
    if name in JUNK_FOLDERS or name in JUNK_FILES:
        return True
    if any(name.startswith(prefix) for prefix in JUNK_PREFIXES):
        return True
    return False


# ------------------------------------------------------------
# ZIP Ìï¥Ï†ú + Ï†ïÎ¶¨ + ÌèâÌÉÑÌôî
# ------------------------------------------------------------
def _extract_zip(zip_path: str, dest: str = None) -> str:
    """
    ZIP ÌååÏùºÏùÑ ÏïïÏ∂ï Ìï¥Ï†úÌïòÍ≥† Ï†ïÎ¶¨Ìï©ÎãàÎã§.
    
    Args:
        zip_path: ZIP ÌååÏùº Í≤ΩÎ°ú
        dest: ÏïïÏ∂ï Ìï¥Ï†ú ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ (NoneÏù¥Î©¥ ÏûêÎèô ÏÉùÏÑ±)
    
    Returns:
        ÏïïÏ∂ï Ìï¥Ï†úÎêú ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú
    """
    if dest is None:
        dest = f"{zip_path}_extracted"
    
    if not os.path.exists(dest):
        os.makedirs(dest, exist_ok=True)
        with zipfile.ZipFile(zip_path, "r") as zf:
            zf.extractall(dest)
        
        # ÏïïÏ∂ï Ìï¥Ï†ú ÌõÑ Ï†ïÎ¶¨
        _cleanup_extracted(dest)
        _flatten_structure(dest, os.path.splitext(os.path.basename(zip_path))[0])
    
    return dest


def _cleanup_extracted(directory: str):
    """
    ÏïïÏ∂ï Ìï¥Ï†úÎêú ÎîîÎ†âÌÜ†Î¶¨ÏóêÏÑú Î∂àÌïÑÏöîÌïú ÌååÏùº/Ìè¥Îçî Ï†úÍ±∞
    
    Ï†úÍ±∞ ÎåÄÏÉÅ:
    - __MACOSX/ Ìè¥Îçî
    - .DS_Store ÌååÏùº
    - ._ Î°ú ÏãúÏûëÌïòÎäî ÌååÏùº (macOS Î¶¨ÏÜåÏä§ Ìè¨ÌÅ¨)
    - Thumbs.db (Windows)
    """
    # 1. Î£®Ìä∏ Î†àÎ≤® Î∂àÌïÑÏöîÌïú Ìè¥Îçî Î®ºÏ†Ä Ï†úÍ±∞
    for item in os.listdir(directory):
        item_path = os.path.join(directory, item)
        if item in JUNK_FOLDERS and os.path.isdir(item_path):
            shutil.rmtree(item_path)
            print(f"üßπ Removed junk folder: {item}")
    
    # 2. Ïû¨Í∑ÄÏ†ÅÏúºÎ°ú Î∂àÌïÑÏöîÌïú ÌååÏùº/Ìè¥Îçî Ï†úÍ±∞
    for root, dirs, files in os.walk(directory, topdown=False):
        # Î∂àÌïÑÏöîÌïú Ìè¥Îçî Ï†úÍ±∞
        for d in dirs:
            if d in JUNK_FOLDERS:
                dir_path = os.path.join(root, d)
                if os.path.exists(dir_path):
                    shutil.rmtree(dir_path)
        
        # Î∂àÌïÑÏöîÌïú ÌååÏùº Ï†úÍ±∞
        for f in files:
            if _is_junk(f):
                file_path = os.path.join(root, f)
                if os.path.exists(file_path):
                    os.remove(file_path)


def _flatten_structure(directory: str, zip_stem: str):
    """
    Ïù¥Ï§ë Ï§ëÏ≤© Íµ¨Ï°∞Î•º ÌèâÌÉÑÌôîÌï©ÎãàÎã§.
    
    ÏòàÏãú:
        Before: extracted/archive/archive/train/
        After:  extracted/train/
    
    Args:
        directory: ÏïïÏ∂ï Ìï¥Ï†úÎêú ÎîîÎ†âÌÜ†Î¶¨
        zip_stem: ZIP ÌååÏùº Ïù¥Î¶Ñ (ÌôïÏû•Ïûê Ï†úÏô∏)
    """
    # Ïà®ÍπÄ ÌååÏùº/Î∂àÌïÑÏöîÌïú ÌååÏùº Ï†úÏô∏Ìïú Ìï≠Î™© Î™©Î°ù
    items = [
        item for item in os.listdir(directory) 
        if not item.startswith('.') and item not in JUNK_FOLDERS
    ]
    
    # Ï†ïÌôïÌûà ÌïòÎÇòÏùò Ìè¥ÎçîÎßå ÏûàÎäî Í≤ΩÏö∞ ÌèâÌÉÑÌôî Í≤ÄÌÜ†
    if len(items) == 1:
        single_item = os.path.join(directory, items[0])
        if os.path.isdir(single_item):
            # ZIP ÌååÏùºÎ™ÖÍ≥º Í∞ôÍ±∞ÎÇò, Ïù¥Ï§ë Ï§ëÏ≤©Ïù∏ Í≤ΩÏö∞ ÌèâÌÉÑÌôî
            if items[0] == zip_stem or _is_double_nested(single_item):
                print(f"üìÇ Flattening nested structure: {items[0]}/")
                _move_contents_up(single_item, directory)


def _is_double_nested(folder: str) -> bool:
    """
    Ïù¥Ï§ë Ï§ëÏ≤© Íµ¨Ï°∞Ïù∏ÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§.
    
    Ìè¥Îçî ÏïàÏóê ÌïòÎÇòÏùò Ìè¥ÎçîÎßå ÏûàÍ≥†, Í∑∏ Ìè¥ÎçîÍ∞Ä Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Î•º Îã¥Í≥† ÏûàÎäîÏßÄ ÌôïÏù∏
    """
    items = [
        item for item in os.listdir(folder) 
        if not item.startswith('.') and item not in JUNK_FOLDERS
    ]
    
    if len(items) == 1 and os.path.isdir(os.path.join(folder, items[0])):
        # ÌïòÏúÑ Ìè¥ÎçîÏóê Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏
        sub_folder = os.path.join(folder, items[0])
        sub_items = [
            item.lower() for item in os.listdir(sub_folder) 
            if not item.startswith('.')
        ]
        data_indicators = ['images', 'labels', 'train', 'valid', 'test', 'data.yaml', 'annotations']
        return any(indicator in sub_items for indicator in data_indicators)
    
    return False


def _move_contents_up(source_dir: str, target_dir: str):
    """
    source_dirÏùò ÎÇ¥Ïö©Î¨ºÏùÑ target_dirÎ°ú Ïù¥ÎèôÌïòÍ≥† source_dir ÏÇ≠Ï†ú
    """
    import uuid
    
    # ÏûÑÏãú ÎîîÎ†âÌÜ†Î¶¨Î°ú Î®ºÏ†Ä Ïù¥Îèô (Ïù¥Î¶Ñ Ï∂©Îèå Î∞©ÏßÄ)
    temp_name = f"_temp_{uuid.uuid4().hex[:8]}"
    temp_dir = os.path.join(os.path.dirname(source_dir), temp_name)
    os.rename(source_dir, temp_dir)
    
    # ÎÇ¥Ïö©Î¨ºÏùÑ ÏÉÅÏúÑÎ°ú Ïù¥Îèô
    for item in os.listdir(temp_dir):
        src = os.path.join(temp_dir, item)
        dst = os.path.join(target_dir, item)
        
        # Ï∂©Îèå Ïãú ÎçÆÏñ¥Ïì∞Í∏∞
        if os.path.exists(dst):
            if os.path.isdir(dst):
                shutil.rmtree(dst)
            else:
                os.remove(dst)
        
        shutil.move(src, dst)
    
    # Îπà ÏûÑÏãú ÎîîÎ†âÌÜ†Î¶¨ Ï†úÍ±∞
    if os.path.exists(temp_dir):
        try:
            os.rmdir(temp_dir)
        except OSError:
            shutil.rmtree(temp_dir)


# ------------------------------------------------------------
# Tree view ÏÉùÏÑ±Í∏∞ (Î∂àÌïÑÏöîÌïú ÌååÏùº/Ìè¥Îçî ÌïÑÌÑ∞ÎßÅ)
# ------------------------------------------------------------
def _build_tree(path: str) -> dict:
    """
    ÎîîÎ†âÌÜ†Î¶¨ Ìä∏Î¶¨ Íµ¨Ï°∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
    Î∂àÌïÑÏöîÌïú ÌååÏùº/Ìè¥Îçî(__MACOSX, .DS_Store Îì±)Îäî Ï†úÏô∏Ìï©ÎãàÎã§.
    """
    name = os.path.basename(path)
    
    # Î∂àÌïÑÏöîÌïú Ìï≠Î™© ÌïÑÌÑ∞ÎßÅ
    if _is_junk(name):
        return None
    
    if os.path.isfile(path):
        return {"name": name}

    children = []
    for item in sorted(os.listdir(path)):
        # Î∂àÌïÑÏöîÌïú Ìï≠Î™© Ïä§ÌÇµ
        if _is_junk(item):
            continue
        
        full = os.path.join(path, item)
        child = _build_tree(full)
        if child is not None:
            children.append(child)

    return {"name": name, "children": children}


# ------------------------------------------------------------
# RoboflowÏö© EDA (class, splitÎ≥Ñ ÌÜµÍ≥Ñ)
# ------------------------------------------------------------
def analyze_roboflow(info: dict) -> dict:
    root = info["root_dir"]
    data_yaml = os.path.join(root, "data.yaml")

    class_names: list[str] = []
    if os.path.exists(data_yaml):
        try:
            with open(data_yaml, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
            names = data.get("names")
            if isinstance(names, list):
                class_names = names
            elif isinstance(names, dict):
                # dictÏùº Í≤ΩÏö∞ index ÏàúÏúºÎ°ú Ï†ïÎ†¨
                class_names = [name for _, name in sorted(names.items(), key=lambda x: int(x[0]))]
        except Exception:
            class_names = []

    splits = {}
    for split in ["train", "valid", "test"]:
        split_dir = os.path.join(root, split)
        if not os.path.isdir(split_dir):
            continue

        images_dir = os.path.join(split_dir, "images")
        labels_dir = os.path.join(split_dir, "labels")

        image_files = []
        label_files = []

        if os.path.isdir(images_dir):
            for r, d, files in os.walk(images_dir):
                for f in files:
                    if os.path.splitext(f)[1].lower() in IMAGE_EXT:
                        image_files.append(os.path.join(r, f))

        if os.path.isdir(labels_dir):
            for r, d, files in os.walk(labels_dir):
                for f in files:
                    if os.path.splitext(f)[1].lower() == ".txt":
                        label_files.append(os.path.join(r, f))

        class_counts = {}
        # YOLO-style ÎùºÎ≤®(txt)Ïù¥Î©¥ Í∞ÑÎã®Ìûà class index ÌÜµÍ≥Ñ
        for lf in label_files:
            try:
                with open(lf, "r", encoding="utf-8") as f:
                    for line in f:
                        parts = line.strip().split()
                        if not parts:
                            continue
                        cls_idx = int(float(parts[0]))
                        class_counts[cls_idx] = class_counts.get(cls_idx, 0) + 1
            except Exception:
                continue

        # class index ‚Üí class name Îß§Ìïë
        class_counts_named = {}
        for idx, cnt in class_counts.items():
            if 0 <= idx < len(class_names):
                cname = class_names[idx]
            else:
                cname = f"class_{idx}"
            class_counts_named[cname] = cnt

        splits[split] = {
            "num_images": len(image_files),
            "num_labels": len(label_files),
            "class_counts": class_counts_named,
        }

    return {
        "classes": class_names,
        "splits": splits,
    }


# ------------------------------------------------------------
# ZIP Íµ¨Ï°∞ ÏûêÎèô Î∂ÑÏÑùÍ∏∞ (YOLO / Roboflow / COCO / VOC / Bundles)
# ------------------------------------------------------------
def analyze_zip_dataset(zip_path: str) -> dict:
    """
    ZIP ÎÇ¥Î∂Ä Íµ¨Ï°∞ Î∂ÑÏÑù ‚Üí zip_type ÌåêÎ≥Ñ (yolo / roboflow / coco / voc / bundles)
    ÎòêÌïú Ï†ÑÏ≤¥ Ìä∏Î¶¨Î∑∞ + sample imageÎèÑ Ìè¨Ìï®
    """
    extracted = _extract_zip(zip_path)
    tree = _build_tree(extracted)

    stats = {
        "total_files": 0,
        "image_files": 0,
        "text_files": 0,
        "csv_files": 0,
        "video_files": 0,
        "json_files": 0,
        "xml_files": 0,
        "subdirs": set(),
    }

    sample_image = None

    for root, dirs, files in os.walk(extracted):
        # Î∂àÌïÑÏöîÌïú ÎîîÎ†âÌÜ†Î¶¨ ÌÉêÏÉâ Ïä§ÌÇµ (in-place ÏàòÏ†ï)
        dirs[:] = [d for d in dirs if not _is_junk(d)]
        
        rel = os.path.relpath(root, extracted)
        if rel != ".":
            top = rel.split(os.sep)[0]
            # Î∂àÌïÑÏöîÌïú Ìè¥Îçî Ï†úÏô∏
            if not _is_junk(top):
                stats["subdirs"].add(top)

        for f in files:
            # Î∂àÌïÑÏöîÌïú ÌååÏùº Ïä§ÌÇµ
            if _is_junk(f):
                continue
            
            stats["total_files"] += 1
            ext = os.path.splitext(f)[1].lower()
            full = os.path.join(root, f)

            if ext in IMAGE_EXT:
                stats["image_files"] += 1
                if sample_image is None:
                    sample_image = full
            elif ext in TEXT_EXT:
                stats["text_files"] += 1
            elif ext in CSV_EXT:
                stats["csv_files"] += 1
            elif ext in VIDEO_EXT:
                stats["video_files"] += 1
            elif ext == ".json":
                stats["json_files"] += 1
            elif ext == ".xml":
                stats["xml_files"] += 1

    stats["subdirs"] = sorted(list(stats["subdirs"]))

    def has_dir(path_rel: str) -> bool:
        return os.path.isdir(os.path.join(extracted, path_rel))

    has_data_yaml = os.path.exists(os.path.join(extracted, "data.yaml"))

    # ------ Roboflow (train/valid/test + images/labels + data.yaml) ------
    if has_data_yaml and (has_dir("train") or has_dir("valid") or has_dir("test")):
        roboflow_like = True
        for split in ["train", "valid", "test"]:
            split_path = os.path.join(extracted, split)
            if os.path.isdir(split_path):
                imgd = os.path.join(split_path, "images")
                lbld = os.path.join(split_path, "labels")
                # ÏùºÎ∂Ä splitÏù¥ ÏóÜÏñ¥ÎèÑ Ï†ÑÏ≤¥Ï†ÅÏúºÎ°úÎäî Roboflow ÎùºÍ≥† Í∞ÑÏ£º
                if not (os.path.isdir(imgd) and os.path.isdir(lbld)):
                    roboflow_like = False
                    break
        if roboflow_like:
            return {
                "zip_type": "roboflow",
                "root_dir": extracted,
                "stats": stats,
                "tree": tree,
                "sample_image": sample_image,
            }

    # ------ YOLO (images + labels) ------
    if has_dir("images") and has_dir("labels"):
        return {
            "zip_type": "yolo",
            "root_dir": extracted,
            "stats": stats,
            "tree": tree,
            "sample_image": sample_image,
        }

    # ------ Pascal VOC ------
    if has_dir("Annotations") and has_dir("JPEGImages"):
        xmls = glob.glob(os.path.join(extracted, "Annotations", "*.xml"))
        jpgs = glob.glob(os.path.join(extracted, "JPEGImages", "*.jpg"))
        if xmls and jpgs:
            return {
                "zip_type": "voc",
                "root_dir": extracted,
                "stats": stats,
                "tree": tree,
                "sample_image": sample_image,
            }

    # ------ COCO ------
    if has_dir("images") and has_dir("annotations"):
        jsons = glob.glob(os.path.join(extracted, "annotations", "*.json"))
        if jsons:
            return {
                "zip_type": "coco",
                "root_dir": extracted,
                "stats": stats,
                "tree": tree,
                "sample_image": sample_image,
            }

    # ------ Bundles ------
    if stats["image_files"] > 0 and stats["csv_files"] == 0 and stats["text_files"] == 0:
        ztype = "image_bundle"
    elif stats["csv_files"] > 0:
        ztype = "tabular_bundle"
    elif stats["text_files"] > 0:
        ztype = "text_bundle"
    else:
        ztype = "unknown_zip"

    return {
        "zip_type": ztype,
        "root_dir": extracted,
        "stats": stats,
        "tree": tree,
        "sample_image": sample_image,
    }

# ---------------------------------------------------------------------
# YOLO / VOC / COCO Î∂ÑÏÑùÍ∏∞ (EDA ÏÉÅÏÑ∏)
# ---------------------------------------------------------------------

def analyze_yolo(info):
    """
    YOLO format:
        extracted/
            images/
            labels/
            data.yaml
    """
    tree = info.get("tree", {})
    stats = info.get("stats", {})
    classes = []

    # data.yaml Î∂ÑÏÑù (ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ)
    yaml_path = None
    for f in stats.get("all_files", []):
        if f.endswith("data.yaml"):
            yaml_path = f
            break

    if yaml_path and os.path.exists(yaml_path):
        import yaml
        with open(yaml_path, "r") as y:
            ydata = yaml.safe_load(y)
            classes = ydata.get("names", []) or ydata.get("names", {})

    return {
        "format": "yolo",
        "classes": classes,
        "num_images": stats.get("image_files", 0),
        "num_labels": stats.get("text_files", 0),
        "tree": tree,
    }


def analyze_voc(info):
    """
    VOC format:
        extracted/
            Annotations/*.xml
            JPEGImages/*.jpg
            ImageSets/Main/*.txt
    """
    stats = info.get("stats", {})
    tree = info.get("tree", {})

    # VOC XML ÌååÏã±ÏúºÎ°ú class ÌÜµÍ≥Ñ
    import xml.etree.ElementTree as ET

    class_count = {}

    for f in stats.get("all_files", []):
        if f.endswith(".xml"):
            try:
                tree_xml = ET.parse(f)
                root = tree_xml.getroot()

                for obj in root.findall("object"):
                    name = obj.find("name").text.strip()
                    class_count[name] = class_count.get(name, 0) + 1
            except Exception:
                pass

    return {
        "format": "voc",
        "num_annotations": sum(class_count.values()),
        "class_distribution": class_count,
        "num_images": stats.get("image_files", 0),
        "tree": tree,
    }


def analyze_coco(info):
    """
    COCO format:
        extracted/
            annotations/*.json
            train2017/
            val2017/
    """
    stats = info.get("stats", {})
    tree = info.get("tree", {})

    import json

    class_count = {}
    total_annotations = 0

    # COCO annotation ÌååÏùº Ï∞æÍ∏∞
    for f in stats.get("all_files", []):
        if f.endswith(".json") and "annotation" in f.lower():
            try:
                with open(f, "r") as j:
                    data = json.load(j)

                categories = {c["id"]: c["name"] for c in data.get("categories", [])}

                for ann in data.get("annotations", []):
                    cls_id = ann["category_id"]
                    cls_name = categories.get(cls_id, "unknown")
                    class_count[cls_name] = class_count.get(cls_name, 0) + 1
                    total_annotations += 1
            except Exception:
                pass

    return {
        "format": "coco",
        "num_annotations": total_annotations,
        "class_distribution": class_count,
        "num_images": stats.get("image_files", 0),
        "tree": tree,
    }